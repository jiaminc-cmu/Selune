# Selune Performance Report

> Auto-generated by `benchmarks/run_benchmarks.sh` on 2026-02-24 23:00:12
> To regenerate: `./benchmarks/run_benchmarks.sh`

# Selune Benchmark Results

**Date:** 2026-02-24 23:00:12
**Machine:** arm64 Apple M3
**OS:** macOS 14.5
**Runs per benchmark:** 3 (best of N)

### Implementations

- **Selune:** ./target/release/selune
- **PUC Lua:** Lua 5.4.8  Copyright (C) 1994-2025 Lua.org, PUC-Rio
- **LuaJIT:** LuaJIT 2.1.1767980792 -- Copyright (C) 2005-2026 Mike Pall. https://luajit.org/

---

## Results

| Benchmark | Selune (s) | PUC Lua (s) | LuaJIT (s) | Selune/PUC | Selune/LuaJIT |
|-----------|-----------|-------------|------------|------------|---------------|
| arithmetic | 6.313929 | 1.798739 | 0.136644 | 3.51x | 46.21x |
| fibonacci | 1.580727 | 0.422298 | 0.040202 | 3.74x | 39.32x |
| ackermann | 9.604873 | 4.156104 | 0.469646 | 2.31x | 20.45x |
| table_array | 0.130643 | 0.052170 | 0.005740 | 2.50x | 22.76x |
| table_hash | 1.307741 | 1.028235 | 0.234739 | 1.27x | 5.57x |
| table_object | 0.795276 | 0.223993 | 0.050617 | 3.55x | 15.71x |
| string_concat | 0.206689 | 0.128598 | 0.054404 | 1.61x | 3.80x |
| string_match | 0.066995 | 0.007707 | 0.006263 | 8.69x | 10.70x |
| string_format | 0.988430 | 0.406950 | 0.125821 | 2.43x | 7.86x |
| closures | 0.359214 | 0.213964 | 0.121747 | 1.68x | 2.95x |
| method_calls | 2.952070 | 0.473474 | 0.051273 | 6.23x | 57.58x |
| coroutines | 0.495000 | 0.131542 | SKIP | 3.76x | â€” |
| gc_pressure | 0.676818 | 0.495536 | 0.069463 | 1.37x | 9.74x |
| binary_trees | 2.003478 | 1.685243 | 0.417378 | 1.19x | 4.80x |
| spectral_norm | 2.462825 | 1.781707 | 0.033209 | 1.38x | 74.16x |
| mandelbrot | 1.840365 | 0.774968 | 0.064933 | 2.37x | 28.34x |

---

**Legend:**
- **Selune/PUC**: ratio of Selune time to PUC Lua time (lower is better for Selune; <1.0x means Selune is faster)
- **Selune/LuaJIT**: ratio of Selune time to LuaJIT time (lower is better for Selune)
- **SKIP**: benchmark not applicable for that implementation
- **FAIL**: benchmark failed to run

## Summary

- **Geometric mean Selune/PUC Lua:** 2.51x (across 16 benchmarks)
- **Geometric mean Selune/LuaJIT:** 14.90x (across 15 benchmarks)


---

## Analysis

### Category Breakdown

| Category | Benchmarks | Notes |
|----------|-----------|-------|
| Arithmetic/Loops | arithmetic, fibonacci, ackermann | Core dispatch loop + integer/float ops |
| Tables | table_array, table_hash, table_object | Array vs hash performance, metatable dispatch |
| Strings | string_concat, string_match, string_format | String interning, pattern engine, formatting |
| Functions | closures, method_calls | Closure creation, upvalue access, OOP dispatch |
| Coroutines | coroutines | Yield/resume overhead (Selune vs PUC only) |
| GC | gc_pressure, binary_trees | Allocation rate, GC pause time, tree traversal |
| Math | spectral_norm, mandelbrot | Float-heavy tight loops |

### JIT Compiler (In Progress)

The JIT compiler (`selune-jit`) uses Cranelift to generate native code for hot functions (called 1000+ times). It currently supports 55+ opcodes with integer and float type specialization:

- **7-11x speedup** over the interpreter on numeric-heavy loops
- Integer/float register allocation with slot caching
- Loop-carried type propagation via Cranelift block parameters
- Side-exit to interpreter for unsupported patterns (metamethods, coroutines, complex table ops)

Note: The benchmarks above measure interpreter performance (each function called once, below JIT threshold). JIT benefits apply to inner loops and frequently-called numeric functions.

### Remaining Optimization Opportunities

- Inline caching for method calls and table lookups
- JIT support for string operations and table access patterns
- Generational GC (selune-core)
- SIMD-accelerated string operations

### How to Profile

#### Using Instruments (macOS)
```bash
# Time Profiler
xcrun xctrace record --template 'Time Profiler' --launch ./target/release/selune benchmarks/scripts/fibonacci.lua
```

#### Using cargo-flamegraph
```bash
cargo install flamegraph
cargo flamegraph --release -- benchmarks/scripts/fibonacci.lua
```

#### Using perf (Linux)
```bash
perf record -g ./target/release/selune benchmarks/scripts/fibonacci.lua
perf report
```

